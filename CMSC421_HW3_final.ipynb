{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeneralCoder365/cmsc421_hw3/blob/main/CMSC421_HW3_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mHPDGaUKS9O"
      },
      "source": [
        "In this homework you'll train a simple image classifier using using Pytorch. If you're not familiar with Pytorch please take a look at our [introduction to Pytorch notebook](https://colab.research.google.com/drive/1GO_YSErd9TjiH0R-hZ2XkKIfMbQK9Ask?usp=sharing). There are four parts to the homework:\n",
        "\n",
        "1. Dataset class: you'll create a custom dataset class that you'll use to load the images for training. Your image transformations should be done in the dataset class.\n",
        "\n",
        "2. Model design: in this section you'll design a simple CNN based model architecture to learn to predict image classes correctly.\n",
        "\n",
        "3. Model training: train an image classifier using the model you designed in step 2. You'll need to instantiate a dataloader that uses an instance of your dataset class to iterate through the dataset for training.\n",
        "\n",
        "4. Evaluation: load your model's weight and run inference on the dataset and report your result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFMMCsSPHXnF",
        "outputId": "06094590-0056-4191-86a9-9c6d886b0b29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-27 00:06:35--  http://cs.umd.edu/~pulkit/hw_3_data.tar.gz\n",
            "Resolving cs.umd.edu (cs.umd.edu)... 128.8.127.4\n",
            "Connecting to cs.umd.edu (cs.umd.edu)|128.8.127.4|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://www.cs.umd.edu/~pulkit/hw_3_data.tar.gz [following]\n",
            "--2024-04-27 00:06:35--  http://www.cs.umd.edu/~pulkit/hw_3_data.tar.gz\n",
            "Resolving www.cs.umd.edu (www.cs.umd.edu)... 128.8.127.4\n",
            "Reusing existing connection to cs.umd.edu:80.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7171530 (6.8M) [application/x-gzip]\n",
            "Saving to: ‘data.tar.gz’\n",
            "\n",
            "data.tar.gz         100%[===================>]   6.84M  4.65MB/s    in 1.5s    \n",
            "\n",
            "2024-04-27 00:06:37 (4.65 MB/s) - ‘data.tar.gz’ saved [7171530/7171530]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tarfile\n",
        "\n",
        "if not os.path.isfile('./data.tar.gz'):\n",
        "    !wget 'http://cs.umd.edu/~pulkit/hw_3_data.tar.gz' -O data.tar.gz\n",
        "\n",
        "with tarfile.open('./data.tar.gz', 'r:gz') as tar:\n",
        "    tar.extractall(path='./')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jwdJ6QNL64y"
      },
      "source": [
        "### Dataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bt-Ur2VKOhj",
        "outputId": "23fdbea8-01ac-415c-f39d-0f932207a451",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      class_id  class_name     image_name                image_path\n",
            "0            0         cat  718jai12.JPEG  data/train/718jai12.JPEG\n",
            "1            0         cat  upajvagf.JPEG  data/train/upajvagf.JPEG\n",
            "2            0         cat  u3di1s04.JPEG  data/train/u3di1s04.JPEG\n",
            "3            0         cat  8p2hg2ln.JPEG  data/train/8p2hg2ln.JPEG\n",
            "4            0         cat  98em9mks.JPEG  data/train/98em9mks.JPEG\n",
            "...        ...         ...            ...                       ...\n",
            "2995         9  guinea_pig  92vqrxoe.JPEG  data/train/92vqrxoe.JPEG\n",
            "2996         9  guinea_pig  s24t07ac.JPEG  data/train/s24t07ac.JPEG\n",
            "2997         9  guinea_pig  4syf2nyz.JPEG  data/train/4syf2nyz.JPEG\n",
            "2998         9  guinea_pig  rhix2ll1.JPEG  data/train/rhix2ll1.JPEG\n",
            "2999         9  guinea_pig  d7shdeik.JPEG  data/train/d7shdeik.JPEG\n",
            "\n",
            "[3000 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "data = pd.read_csv('/content/data/csvs/train.csv')\n",
        "print(data)\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, csv_path, data_root, transform=None, device='cpu'):\n",
        "        self.transform = transform\n",
        "        self.root_path = data_root\n",
        "        self.device = device\n",
        "\n",
        "        # TODO: Read the csv file. You can use the pandas library\n",
        "        data = pd.read_csv(data_root)\n",
        "\n",
        "        # TODO : Get the image paths from the csv\n",
        "        self.image_paths = data[\"image_path\"]\n",
        "\n",
        "        # TODO: Get the class ids from the csv. You might want to check if the class_id\n",
        "        # column exists in the csv before trying to get it. The test csv does not have\n",
        "        # the class_id column\n",
        "        self.class_ids = data[\"class_id\"]\n",
        "\n",
        "        # TODO: Get the image names from the csv. This is required for the test part at\n",
        "        # the end of the notebook. You should only return the image name for testing,\n",
        "        # otherwise you should return the image and the class id\n",
        "        self.image_names = data[\"image_name\"]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        rel_img_path = self.image_paths[idx]\n",
        "        image_name = self.image_names[idx]\n",
        "\n",
        "        # TODO: Read the image file\n",
        "        img = None\n",
        "\n",
        "        # TODO Apply transformations if any to the image. You will want to at least convert\n",
        "        # the image to a tensor. You can also apply other transformations.\n",
        "\n",
        "        if self.class_ids is None: # for testing purposes\n",
        "            return img, image_name, rel_img_path\n",
        "        else:\n",
        "            class_id = torch.tensor(self.class_ids[idx], dtype=torch.long)\n",
        "            return img.to(self.device), class_id.to(self.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwbZlP1UQoN1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms as T\n",
        "\n",
        "def plot_image(img, title=None):\n",
        "    plt.imshow(img)\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# TODO: Create an instance of the CustomImageDataset class for the training dataset\n",
        "dataset = None\n",
        "\n",
        "# TODO: Show the first 3 images from the dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtFIz_pdRcJ6"
      },
      "source": [
        "### Model definition\n",
        "\n",
        "Define your image classifier model here. Since we're working with images, you should consider an convolution neural network type model architecture. Start simple and make it more complex if you need to once you have something working."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UR-UqnCNRhWE"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ImageClassifier(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        # TODO: Create one or more convolutional neural network layers. This is just a suggestion.\n",
        "        self.conv = None\n",
        "\n",
        "        # TODO: Create one or more feed forward layers. This is just a suggestion.\n",
        "        self.ff = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        return self.ff(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK-lrVzeWgvs"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WF0QMXRCWi-0"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torch.optim import Adam\n",
        "import torchvision.transforms as T\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Feel free to try other batch sizes. The batch size is usually a power of 2.\n",
        "batch_size = 16\n",
        "\n",
        "# You can try other learning rates to see how it affects the training.\n",
        "learning_rate = 1e-4\n",
        "\n",
        "# Try to explore different transformation functions. You can use transformations\n",
        "# to make your model more robust to translation, color changes etc. This is a good\n",
        "# article that explains some transformations available in Pytorch\n",
        "# https://pytorch.org/vision/stable/transforms.html. You can use transformations\n",
        "# to augment/\"increase\" your training data.\n",
        "transform = None\n",
        "\n",
        "img_root = \"./\"\n",
        "\n",
        "# TODO: Create an instance of the CustomImageDataset class for the training and validation datasets\n",
        "train_set = None\n",
        "val_set = None\n",
        "\n",
        "# TODO: Create two dataloaders for bothe datasets.\n",
        "# TODO: Shuffle the training dataloader. This is important to prevent the model from learning the order of the data.\n",
        "train_loader = None\n",
        "val_loader = None\n",
        "\n",
        "# TODO: Initialize your model\n",
        "n_classes = 10\n",
        "model = None\n",
        "\n",
        "# TODO: Initialize the optimizer. Feel free to try other optimizers in the torch.optim\n",
        "# module.\n",
        "# Hint: the Adam optimizer and its variants are the staple these days.\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# TODO: Instantiate the loss function.\n",
        "# Hint: Cross entropy loss works great for classification tasks like this one.\n",
        "# Reading up on what loss function to use for what task could be informative\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "eval_every = 2\n",
        "\n",
        "# Consider training for longer. Keep an eye on the validation loss and decide\n",
        "# on what works best for you.\n",
        "n_epochs = 10\n",
        "val_loss_values = []\n",
        "training_loss_values = []\n",
        "eval_epochs = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # set your model to training mode. This is important if you're using normalization\n",
        "    # or dropout\n",
        "    model.train()\n",
        "    for img, label in tqdm(train_loader):\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # TODO: Make a forward pass (predict the class of the image)\n",
        "        pred = None\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = None\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation loop\n",
        "    if epoch > 0 and epoch % eval_every == 0:\n",
        "        model.eval()\n",
        "        # don't calculate gradients when evaluating your model\n",
        "        with torch.no_grad():\n",
        "            for img, label in tqdm(val_loader):\n",
        "                pred = None\n",
        "                val_loss = None\n",
        "\n",
        "        print(f\"Epoch: {epoch}, Train Loss: {loss.item()} Eval Loss: {val_loss.item()}\")\n",
        "        eval_epochs.append(epoch)\n",
        "        training_loss_values.append(loss.item())\n",
        "        val_loss_values.append(val_loss.item())\n",
        "\n",
        "\n",
        "# Save your model's weights\n",
        "torch.save(model.state_dict(), \"model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ4yoS8JDqE6"
      },
      "source": [
        "### Plot your training and validation loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVFpiEPbDqE7"
      },
      "outputs": [],
      "source": [
        "# Plot the training and validation loss\n",
        "plt.plot(eval_epochs, training_loss_values, label='Training loss')\n",
        "plt.plot(eval_epochs, val_loss_values, label='Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K082PbS4xpbW"
      },
      "source": [
        "### Test your model against the validation dataset\n",
        "This should give you a rough idea on how your model will do on the test set that you don't have labels for.\n",
        "This section is not required and is only provided as a sanity check for you"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9rJjPJs1tno"
      },
      "outputs": [],
      "source": [
        "## Load from your saved model\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Load from your saved model using torch.load\n",
        "model_state_dict = torch.load(\"./model.pth\")\n",
        "model = None\n",
        "model.load_state_dict(model_state_dict)\n",
        "\n",
        "# set model to inference mode\n",
        "model.eval()\n",
        "batch_size = 1\n",
        "\n",
        "# Load the validation dataset\n",
        "test_dataset = None\n",
        "test_loader = None\n",
        "\n",
        "preds = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for img, label in tqdm(test_loader):\n",
        "        # TODO: predict the classes of the images and append them to the preds list\n",
        "        pass\n",
        "\n",
        "# Get the true labels for the validation dataset\n",
        "true_labels = None\n",
        "\n",
        "accuracy = (true_labels == torch.tensor(preds)).float().mean().item()\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8fLnrflZ0bY"
      },
      "source": [
        "### Evaluation\n",
        "Evaluate your model on the test dataset and create a CSF file. This is the file you need to submit.\n",
        "> Important: make sure the prediction file has the columns: image_name, prediction, image_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVoWLoSBZ26n"
      },
      "outputs": [],
      "source": [
        "## Load from your saved model\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Load from your saved model using torch.load\n",
        "model_state_dict = torch.load(\"./model.pth\")\n",
        "model = None\n",
        "model.load_state_dict(model_state_dict)\n",
        "\n",
        "# set model to inference mode\n",
        "model.eval()\n",
        "\n",
        "# Load the test data\n",
        "test_dataset = None\n",
        "\n",
        "# TODO: Create a DataLoader for the test dataset\n",
        "test_loader = None\n",
        "\n",
        "# TODO: Predict and save output to a CSV file. We are just looking for the top class predicted\n",
        "# Hint: Lookup argmax.\n",
        "final_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for img, img_names, img_paths in tqdm(test_loader):\n",
        "        pred = None\n",
        "        # For every element in the batch, get its predicted class id in `pred`\n",
        "        # Class ID will be in int.\n",
        "        batch_preds = [\n",
        "            (img_name, pred_img, img_path)\n",
        "            for (img_name, pred_img, img_path) in zip(img_names, pred, img_paths)\n",
        "        ]\n",
        "        final_preds.extend(batch_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YwTrORz9Z9I"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY\n",
        "test_prediction = pd.DataFrame(final_preds, columns=['image_name', 'prediction', 'image_path'])\n",
        "test_prediction.to_csv('prediction.csv')\n",
        "\n",
        "# You can comment these lines out if you're running the notebook locally\n",
        "from google.colab import files\n",
        "files.download('prediction.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload *prediction.csv* on gradescope"
      ],
      "metadata": {
        "id": "ao_JoY-TExSr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kDe6XxXbE3Jj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}